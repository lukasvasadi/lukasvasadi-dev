import{s as B,n as M}from"./scheduler.be0e0057.js";import{S as F,i as K,g as s,s as i,H as Q,h as o,D as l,c as p,j as J,G as W,f as n,k as X,a}from"./index.c7c9b348.js";function Y(R){let c,A='<img src="/images/nvidia-gpu.jpg" alt="NVIDIA graphics cards"/>',x,u,q="Contents",y,r,D='<li><a href="#introduction">Introduction</a></li> <li><a href="#compiling-for-the-cpu">Compiling for the CPU</a></li>',b,m,N='<a id="introduction">Introduction</a>',w,h,j="CUDA is a C/C++ API that allows developers to access the GPU for accelerated computing. For Python, the most performant option to target the GPU is the <code>pyCUDA</code> library, which exposes the entire CUDA API, but requires writing C code in docstrings. An attractive alternative is using the <code>Numba</code> library, which provides a <strong><em>just-in-time</em></strong> compiling function decorator. This allows the optimization of certain functions that handle data processing without changing the entire program, and without mixing C source code.",H,d,G="Requirements",_,f,E="<li>NVIDIA GPU with CUDA support</li> <li>Python ≥3.4</li> <li>NumPy ≥1.10</li>",P,k,V='<a id="compiling-for-the-cpu">Compiling for the CPU</a>',T,C,O="In addition to compiling Python functions for the GPU, by default, Numba targets the CPU.",L,v,U,S=`<code class="language-python"><span class="token keyword">from</span> numba <span class="token keyword">import</span> jit
<span class="token keyword">import</span> math

<span class="token decorator annotation punctuation">@jit</span>
<span class="token keyword">def</span> <span class="token function">hypot</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Implementation from https://en.wikipedia.org/wiki/Hypot</span>
    x <span class="token operator">=</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    y <span class="token operator">=</span> <span class="token builtin">abs</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    t <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    x <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    t <span class="token operator">=</span> t <span class="token operator">/</span> x
    <span class="token keyword">return</span> x <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>t<span class="token operator">*</span>t<span class="token punctuation">)</span></code>`,I,g,z="<p><strong><em>NOTE:</em></strong> Depending on the GPU, the performance of calculations with <code>float32</code> and <code>float64</code> data types can be significantly different. If the calculation does not require 64-bit precision, NVIDIA recommends using <code>float32</code>. (Most modern operating systems default the value of floating point numbers to 64-bit!)</p>";return{c(){c=s("p"),c.innerHTML=A,x=i(),u=s("h2"),u.textContent=q,y=i(),r=s("ul"),r.innerHTML=D,b=i(),m=s("h2"),m.innerHTML=N,w=i(),h=s("p"),h.innerHTML=j,H=i(),d=s("h3"),d.textContent=G,_=i(),f=s("ul"),f.innerHTML=E,P=i(),k=s("h2"),k.innerHTML=V,T=i(),C=s("p"),C.textContent=O,L=i(),v=s("pre"),U=new Q(!1),I=i(),g=s("blockquote"),g.innerHTML=z,this.h()},l(t){c=o(t,"P",{"data-svelte-h":!0}),l(c)!=="svelte-hte7b2"&&(c.innerHTML=A),x=p(t),u=o(t,"H2",{"data-svelte-h":!0}),l(u)!=="svelte-jpxk5s"&&(u.textContent=q),y=p(t),r=o(t,"UL",{"data-svelte-h":!0}),l(r)!=="svelte-n2dl39"&&(r.innerHTML=D),b=p(t),m=o(t,"H2",{"data-svelte-h":!0}),l(m)!=="svelte-117zo8l"&&(m.innerHTML=N),w=p(t),h=o(t,"P",{"data-svelte-h":!0}),l(h)!=="svelte-1pga5c9"&&(h.innerHTML=j),H=p(t),d=o(t,"H3",{"data-svelte-h":!0}),l(d)!=="svelte-uvqqyo"&&(d.textContent=G),_=p(t),f=o(t,"UL",{"data-svelte-h":!0}),l(f)!=="svelte-1bwh0wc"&&(f.innerHTML=E),P=p(t),k=o(t,"H2",{"data-svelte-h":!0}),l(k)!=="svelte-1ji3g9s"&&(k.innerHTML=V),T=p(t),C=o(t,"P",{"data-svelte-h":!0}),l(C)!=="svelte-vpt7ip"&&(C.textContent=O),L=p(t),v=o(t,"PRE",{class:!0});var e=J(v);U=W(e,!1),e.forEach(n),I=p(t),g=o(t,"BLOCKQUOTE",{"data-svelte-h":!0}),l(g)!=="svelte-1cqqqms"&&(g.innerHTML=z),this.h()},h(){U.a=null,X(v,"class","language-python")},m(t,e){a(t,c,e),a(t,x,e),a(t,u,e),a(t,y,e),a(t,r,e),a(t,b,e),a(t,m,e),a(t,w,e),a(t,h,e),a(t,H,e),a(t,d,e),a(t,_,e),a(t,f,e),a(t,P,e),a(t,k,e),a(t,T,e),a(t,C,e),a(t,L,e),a(t,v,e),U.m(S,v),a(t,I,e),a(t,g,e)},p:M,i:M,o:M,d(t){t&&(n(c),n(x),n(u),n(y),n(r),n(b),n(m),n(w),n(h),n(H),n(d),n(_),n(f),n(P),n(k),n(T),n(C),n(L),n(v),n(I),n(g))}}}const tt={title:"Accelerated computing with CUDA and Python",description:"Enhance data science with rapid parallel processing.",date:"2023-8-31",image:"/images/nvidia-gpu.jpg",categories:["NVIDIA","CUDA","Numba"],published:!1};class et extends F{constructor(c){super(),K(this,c,null,Y,B,{})}}export{et as default,tt as metadata};
